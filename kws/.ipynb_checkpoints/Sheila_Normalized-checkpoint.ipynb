{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtA5YPo9jQHK"
   },
   "source": [
    "# Neural Network for Keyword Spotting on Microncontrollers\n",
    "\n",
    "This notebook provides the code for training a Neural Network to be able to recognize spoken workds. This task is commonly referred as Keyword Spotting (KWS).\n",
    "\n",
    "The goal of this notebook is to build a small enough model to be executed on microcontrollers, where computational power, energy consumption and memory availability are constraints to be taken into account.\n",
    "\n",
    "## A note on datasets\n",
    "\n",
    "In order to train the network in this notebook, you need to have a dataset ready to be processed. This notebook requires an audio dataset made of 1-second long audio samples converted into MFCC Spectrograms in the shape of (49,40,1), meaning that each spectrogram must be an image of size 49x40 with only 1 channel (black/white), and saved in a .npz file.\n",
    "\n",
    "A notebook to convert audio data into a dataset ready to be processed by this notebook is provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3IWygOvCLBmS"
   },
   "source": [
    "## Libraries Import\n",
    "\n",
    "First of all, let's import the needed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rCcpq2MXjPgG",
    "outputId": "32146a1b-23e2-4ec0-d4e7-28c29f52c03b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-23 17:28:49.174455: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-23 17:28:49.225468: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-23 17:28:50.021433: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "#Tensorflow import\n",
    "import tensorflow as tf\n",
    "#Numpy import\n",
    "import numpy as np\n",
    "#Matplotlib import\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "#Math import\n",
    "import math\n",
    "\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import shutil\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6bzD5MuMVIa"
   },
   "source": [
    "Before continuing, let's set the seed to the random numbers generator. This will allow us to have reproducible results between different executions of this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fSDdFpuQU8n_"
   },
   "outputs": [],
   "source": [
    "# Random seed for reproducibility\n",
    "\n",
    "seed = 22 #Choose a fixed seed to have reproducible results (22=Gonzales o Chiesa)\n",
    "\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-91TM9JLvKe"
   },
   "source": [
    "## Dataset Import and Loading\n",
    "\n",
    "If the datast that you want to use is located in your Google Drive, execute the following cell to get access to the drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pavFcZoKxXea",
    "outputId": "9cd702e4-836d-40a0-e2a1-1722398ca30b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oODxdDLiL5pQ"
   },
   "source": [
    "Unpack the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "m6mGEbnGeX-w"
   },
   "outputs": [],
   "source": [
    "#If the dataset is in your Google Drive:\n",
    "#shutil.unpack_archive(\"/content/drive/MyDrive/Tesi/Datasets/preprocessed_dataset.zip\", \"dataset\")\n",
    "#If the dataset has to be uploaded:\n",
    "shutil.unpack_archive(\"sheila_normalized_dataset.zip\", \"dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Lm0ISmfL8-V"
   },
   "source": [
    "Read the .json file associated to the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ooi8mPnFelhA",
    "outputId": "9da0306a-0b44-4ae8-8481-9002e5cf86a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classes': ['silence', 'unknown', 'sheila'], 'train_samples_num': 4817, 'testing_samples_num': 603, 'validation_samples_num': 602, 'representative_samples_num': 61, 'data_shape': [49, 40, 1]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "with open(\"dataset/content/dataset_info.json\", 'r') as openfile:\n",
    " \n",
    "    # Reading from json file\n",
    "    dataset_info = json.load(openfile)\n",
    " \n",
    "print(dataset_info)\n",
    "\n",
    "wanted_words = dataset_info['classes']\n",
    "n_train_samples = dataset_info['train_samples_num']\n",
    "n_testing_samples = dataset_info['testing_samples_num']\n",
    "n_validation_samples = dataset_info['validation_samples_num']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXZllnpxoNEs"
   },
   "source": [
    "The dataset contains training, testing and validation sets. It also provides a representative dataset if a quantization of the model needs to be performed. \n",
    "\n",
    "Load each set into X (inputs) and y (outputs) arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-ZWTz_pQfvII"
   },
   "outputs": [],
   "source": [
    "# Loading .npz files\n",
    "train_dir = \"dataset/content/train.npz\"\n",
    "training_npz = np.load(train_dir)\n",
    "x_train, y_train = training_npz['arr_0'], training_npz['arr_1']\n",
    "\n",
    "val_dir = \"dataset/content/validation.npz\"\n",
    "validation_npz = np.load(val_dir)\n",
    "x_val, y_val = validation_npz['arr_0'], validation_npz['arr_1']\n",
    "\n",
    "testing_dir = \"dataset/content/testing.npz\"\n",
    "testing_npz = np.load(testing_dir)\n",
    "x_test, y_test = testing_npz['arr_0'], testing_npz['arr_1']\n",
    "\n",
    "representative_dir = \"dataset/content/representative.npz\"\n",
    "representative_npz = np.load(representative_dir)\n",
    "x_rep, y_rep = representative_npz['arr_0'], representative_npz['arr_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNU6YtAJNHhi"
   },
   "source": [
    "## Neural Network Design\n",
    "\n",
    "The next section will allow you to design a Neural Network. There is no golden rule, so feel free to experiment with different architectures. \n",
    "\n",
    "Since MFCC spectrograms can be considered images, we will perform an image classification task, trying to associate each spectrogram with the word it represents. Convolutional Neural Networks have shown very good results in accomplishing image classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "myEtH6R9Npui"
   },
   "source": [
    "The first thing to do is define a Data Generator: it is a function that takes care of sending the data to the Neural Network during training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "TRVMV4WbbS7h"
   },
   "outputs": [],
   "source": [
    "class DataGenerator(tfk.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, data, labels, n_samples, batch_size, dim, n_channels,\n",
    "                 n_classes, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.n_samples = n_samples\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(self.n_samples / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # Find list of IDs\n",
    "        samples_list_temp = indexes\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(samples_list_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(self.n_samples)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, samples_list_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, sample in enumerate(samples_list_temp):\n",
    "            # Store sample\n",
    "            mfcc = self.data[sample].reshape(49,40,1)\n",
    "            X[i,] = mfcc\n",
    "            # Store class\n",
    "            y[i] = self.labels[sample]\n",
    "\n",
    "        return X, tfk.utils.to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lz-OrYtYN5qW"
   },
   "source": [
    "Now we instantiate the generators for each set: training, testing and validation. \n",
    "\n",
    "In this section we also specify the batch size to be used during training. The batch size is the number of training samples that the network processes before updating its weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PXKhaC10qYAm",
    "outputId": "d76ec958-2385-46ce-bb13-47bb896dc5f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network input shape: (8, 49, 40, 1)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "n_classes = len(wanted_words)\n",
    "spectrogram_size = (49,40,)\n",
    "spectrogram_channels = 1\n",
    "\n",
    "# Parameters\n",
    "params = {'dim': spectrogram_size,\n",
    "          'batch_size': batch_size,\n",
    "          'n_classes': n_classes,\n",
    "          'n_channels': spectrogram_channels,\n",
    "          'shuffle': True}\n",
    "\n",
    "\n",
    "# Generators\n",
    "training_generator = DataGenerator(x_train, y_train, n_samples=n_train_samples, **params)\n",
    "validation_generator = DataGenerator(x_val, y_val, n_samples=n_validation_samples, **params)\n",
    "testing_generator = DataGenerator(x_test, y_test, n_samples=n_testing_samples, **params)\n",
    "\n",
    "example_spectrogram = training_generator.__getitem__(0)[0]\n",
    "print(\"Neural Network input shape: \" + str(example_spectrogram.shape)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFT_bvHWOS5b"
   },
   "source": [
    "It is now time to build the Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_lxcoqaqqgfY"
   },
   "outputs": [],
   "source": [
    "input_shape = (*spectrogram_size, spectrogram_channels) #do not modify\n",
    "\n",
    "# Assign the name you want to your model\n",
    "model_name = 'Sheila-NormDoubleConvModel'\n",
    "\n",
    "# Build your model here:\n",
    "def build_model(input_shape):\n",
    "\n",
    "  input_layer = tfkl.Input(shape=input_shape, \n",
    "                           name='Input')\n",
    "  \n",
    "  conv_layer = tfkl.Conv2D(\n",
    "              filters=16,\n",
    "              kernel_size=(8, 20),\n",
    "              strides = (2, 2),\n",
    "              padding = 'same',\n",
    "              input_shape=input_shape,\n",
    "              use_bias = True,\n",
    "              activation='relu',\n",
    "              data_format = 'channels_last',\n",
    "              kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
    "    )(input_layer)\n",
    "\n",
    "  maxpool_layer = tfkl.MaxPooling2D(pool_size=(2, 2), padding=\"valid\")(conv_layer)\n",
    "\n",
    "  conv_layer_2 = tfkl.Conv2D(\n",
    "              filters=32,\n",
    "              kernel_size=(4, 10),\n",
    "              strides = (1, 1),\n",
    "              padding = 'same',\n",
    "              input_shape=input_shape,\n",
    "              use_bias = True,\n",
    "              activation='relu',\n",
    "              data_format = 'channels_last',\n",
    "              kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
    "    )(maxpool_layer)\n",
    "\n",
    "  maxpool_layer_2 = tfkl.MaxPooling2D(pool_size=(2,2), padding='valid')(conv_layer_2)\n",
    "\n",
    "  flattening_layer = tfkl.Flatten()(maxpool_layer_2)\n",
    "\n",
    "  output = output_layer = tfkl.Dense(\n",
    "                    units=n_classes, \n",
    "                    activation='softmax', \n",
    "                    kernel_initializer=tfk.initializers.GlorotUniform(seed),\n",
    "                    use_bias = True, \n",
    "                    name='Output')(flattening_layer)\n",
    "\n",
    "  # Connect input and output through the Model class\n",
    "  model = tfk.Model(inputs=input_layer, outputs=output_layer, name=model_name)\n",
    "\n",
    "  optimizer = tfk.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "  # Compile the model\n",
    "  model.compile(loss=tfk.losses.CategoricalCrossentropy(), \n",
    "                optimizer=optimizer, \n",
    "                metrics='accuracy')\n",
    "\n",
    "  # Return the model\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxQ7uC_iOYuR"
   },
   "source": [
    "Compile the network we just built and print a summary with the number of parameters, the layers and input/output shapes of each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GwVTxA87qj2B",
    "outputId": "0606295d-c5d0-461e-fde9-43eeef19e3ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sheila-NormDoubleConvModel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 49, 40, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 25, 20, 16)        2576      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 10, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 12, 10, 32)        20512     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 5, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 960)               0         \n",
      "                                                                 \n",
      " Output (Dense)              (None, 3)                 2883      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,971\n",
      "Trainable params: 25,971\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-23 17:30:20.291422: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-23 17:30:20.317887: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-23 17:30:20.317957: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-23 17:30:20.324696: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-23 17:30:20.324763: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-23 17:30:20.324793: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-23 17:30:21.449752: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-23 17:30:21.449870: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-23 17:30:21.449880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-07-23 17:30:21.449919: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-23 17:30:21.449959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1562 MB memory:  -> device: 0, name: NVIDIA RTX A1000 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model = build_model(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baRWCZy4OheD"
   },
   "source": [
    "## Training the Neural Network\n",
    "\n",
    "This section will train the neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YH9sMo2WOoyn"
   },
   "source": [
    "First of all, we define some callback functions to be executed at the end of each epoch. Remember that an epoch is a single pass through the entire dataset during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "uU5Izt4zMsjB"
   },
   "outputs": [],
   "source": [
    "# Utility function to create folders and callbacks for training\n",
    "from datetime import datetime\n",
    "\n",
    "def create_folders_and_callbacks(model_name):\n",
    "\n",
    "  exps_dir = \"callback_folder\"\n",
    "  if not os.path.exists(exps_dir):\n",
    "      os.makedirs(exps_dir)\n",
    "\n",
    "  now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "\n",
    "  exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
    "  if not os.path.exists(exp_dir):\n",
    "      os.makedirs(exp_dir)\n",
    "      \n",
    "  callbacks = []\n",
    "\n",
    "  # Model checkpoint\n",
    "  # ----------------\n",
    "  ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
    "  if not os.path.exists(ckpt_dir):\n",
    "      os.makedirs(ckpt_dir)\n",
    "\n",
    "  ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'), \n",
    "                                                     save_weights_only=False, # True to save only weights\n",
    "                                                     save_best_only=False) # True to save only the best epoch \n",
    "  callbacks.append(ckpt_callback)\n",
    "\n",
    "  # Visualize Learning on Tensorboard\n",
    "  # ---------------------------------\n",
    "  tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "  if not os.path.exists(tb_dir):\n",
    "      os.makedirs(tb_dir)\n",
    "      \n",
    "  # By default shows losses and metrics for both training and validation\n",
    "  tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir, \n",
    "                                               profile_batch=0,\n",
    "                                               histogram_freq=1)  # if > 0 (epochs) shows weights histograms\n",
    "  callbacks.append(tb_callback)\n",
    "\n",
    "  # Early Stopping\n",
    "  # --------------\n",
    "  es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "  callbacks.append(es_callback)\n",
    "\n",
    "  return callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZqPUdtiO0v1"
   },
   "source": [
    "Define a number of epochs to train you network, and then start the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FBTz_U1KqokQ",
    "outputId": "9a656604-5b6b-443b-99c3-fcd904583a47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-23 17:30:52.939271: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-07-23 17:30:56.411088: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-07-23 17:30:59.384191: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-07-23 17:30:59.860909: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-07-23 17:30:59.871431: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fd9639f2040 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-23 17:30:59.871476: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA RTX A1000 Laptop GPU, Compute Capability 8.6\n",
      "2023-07-23 17:30:59.905817: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-07-23 17:31:00.209472: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-07-23 17:31:00.296734: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/602 [============================>.] - ETA: 0s - loss: 0.6653 - accuracy: 0.7546"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-23 17:31:06.680694: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 16s 11ms/step - loss: 0.6641 - accuracy: 0.7550 - val_loss: 0.3101 - val_accuracy: 0.9067\n",
      "Epoch 2/200\n",
      "599/602 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8644"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 7s 11ms/step - loss: 0.3879 - accuracy: 0.8634 - val_loss: 0.2353 - val_accuracy: 0.9350\n",
      "Epoch 3/200\n",
      "601/602 [============================>.] - ETA: 0s - loss: 0.3336 - accuracy: 0.8866"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 7s 12ms/step - loss: 0.3332 - accuracy: 0.8868 - val_loss: 0.1901 - val_accuracy: 0.9367\n",
      "Epoch 4/200\n",
      "602/602 [==============================] - ETA: 0s - loss: 0.2986 - accuracy: 0.8983"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 7s 12ms/step - loss: 0.2986 - accuracy: 0.8983 - val_loss: 0.1898 - val_accuracy: 0.9367\n",
      "Epoch 5/200\n",
      "599/602 [============================>.] - ETA: 0s - loss: 0.2756 - accuracy: 0.9051"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 7s 12ms/step - loss: 0.2753 - accuracy: 0.9051 - val_loss: 0.1702 - val_accuracy: 0.9417\n",
      "Epoch 6/200\n",
      "599/602 [============================>.] - ETA: 0s - loss: 0.2535 - accuracy: 0.9155"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 7s 12ms/step - loss: 0.2527 - accuracy: 0.9157 - val_loss: 0.2028 - val_accuracy: 0.9383\n",
      "Epoch 7/200\n",
      "600/602 [============================>.] - ETA: 0s - loss: 0.2438 - accuracy: 0.9179"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 8s 13ms/step - loss: 0.2434 - accuracy: 0.9180 - val_loss: 0.1492 - val_accuracy: 0.9533\n",
      "Epoch 8/200\n",
      "599/602 [============================>.] - ETA: 0s - loss: 0.2300 - accuracy: 0.9247"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 8s 12ms/step - loss: 0.2301 - accuracy: 0.9246 - val_loss: 0.1478 - val_accuracy: 0.9517\n",
      "Epoch 9/200\n",
      "599/602 [============================>.] - ETA: 0s - loss: 0.2161 - accuracy: 0.9270"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 8s 13ms/step - loss: 0.2158 - accuracy: 0.9271 - val_loss: 0.1447 - val_accuracy: 0.9517\n",
      "Epoch 10/200\n",
      "597/602 [============================>.] - ETA: 0s - loss: 0.2056 - accuracy: 0.9328"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 7s 12ms/step - loss: 0.2056 - accuracy: 0.9329 - val_loss: 0.1610 - val_accuracy: 0.9500\n",
      "Epoch 11/200\n",
      "597/602 [============================>.] - ETA: 0s - loss: 0.1980 - accuracy: 0.9330"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 7s 12ms/step - loss: 0.1979 - accuracy: 0.9331 - val_loss: 0.1405 - val_accuracy: 0.9533\n",
      "Epoch 12/200\n",
      "600/602 [============================>.] - ETA: 0s - loss: 0.1865 - accuracy: 0.9358"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 7s 12ms/step - loss: 0.1860 - accuracy: 0.9360 - val_loss: 0.1399 - val_accuracy: 0.9500\n",
      "Epoch 13/200\n",
      "602/602 [==============================] - ETA: 0s - loss: 0.1786 - accuracy: 0.9402"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 8s 13ms/step - loss: 0.1786 - accuracy: 0.9402 - val_loss: 0.1374 - val_accuracy: 0.9583\n",
      "Epoch 14/200\n",
      "597/602 [============================>.] - ETA: 0s - loss: 0.1748 - accuracy: 0.9430"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 7s 12ms/step - loss: 0.1745 - accuracy: 0.9431 - val_loss: 0.1309 - val_accuracy: 0.9583\n",
      "Epoch 15/200\n",
      "600/602 [============================>.] - ETA: 0s - loss: 0.1651 - accuracy: 0.9454"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 7s 12ms/step - loss: 0.1648 - accuracy: 0.9456 - val_loss: 0.1247 - val_accuracy: 0.9600\n",
      "Epoch 16/200\n",
      "601/602 [============================>.] - ETA: 0s - loss: 0.1592 - accuracy: 0.9453"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 7s 12ms/step - loss: 0.1591 - accuracy: 0.9454 - val_loss: 0.1435 - val_accuracy: 0.9533\n",
      "Epoch 17/200\n",
      "598/602 [============================>.] - ETA: 0s - loss: 0.1514 - accuracy: 0.9492"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 7s 11ms/step - loss: 0.1524 - accuracy: 0.9491 - val_loss: 0.1390 - val_accuracy: 0.9583\n",
      "Epoch 18/200\n",
      "598/602 [============================>.] - ETA: 0s - loss: 0.1497 - accuracy: 0.9490"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 7s 12ms/step - loss: 0.1491 - accuracy: 0.9493 - val_loss: 0.1299 - val_accuracy: 0.9600\n",
      "Epoch 19/200\n",
      "602/602 [==============================] - ETA: 0s - loss: 0.1430 - accuracy: 0.9510"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 7s 11ms/step - loss: 0.1430 - accuracy: 0.9510 - val_loss: 0.1235 - val_accuracy: 0.9600\n",
      "Epoch 20/200\n",
      "600/602 [============================>.] - ETA: 0s - loss: 0.1380 - accuracy: 0.9556"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 7s 11ms/step - loss: 0.1381 - accuracy: 0.9556 - val_loss: 0.1270 - val_accuracy: 0.9617\n",
      "Epoch 21/200\n",
      "602/602 [==============================] - ETA: 0s - loss: 0.1316 - accuracy: 0.9554"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 7s 11ms/step - loss: 0.1316 - accuracy: 0.9554 - val_loss: 0.1238 - val_accuracy: 0.9583\n",
      "Epoch 22/200\n",
      "602/602 [==============================] - ETA: 0s - loss: 0.1270 - accuracy: 0.9572"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 7s 11ms/step - loss: 0.1270 - accuracy: 0.9572 - val_loss: 0.1398 - val_accuracy: 0.9550\n",
      "Epoch 23/200\n",
      "602/602 [==============================] - ETA: 0s - loss: 0.1226 - accuracy: 0.9589"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 7s 11ms/step - loss: 0.1226 - accuracy: 0.9589 - val_loss: 0.1383 - val_accuracy: 0.9600\n",
      "Epoch 24/200\n",
      "599/602 [============================>.] - ETA: 0s - loss: 0.1152 - accuracy: 0.9626"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 7s 11ms/step - loss: 0.1156 - accuracy: 0.9624 - val_loss: 0.1312 - val_accuracy: 0.9650\n",
      "Epoch 25/200\n",
      "599/602 [============================>.] - ETA: 0s - loss: 0.1140 - accuracy: 0.9622"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 7s 12ms/step - loss: 0.1136 - accuracy: 0.9624 - val_loss: 0.1321 - val_accuracy: 0.9633\n",
      "Epoch 26/200\n",
      "598/602 [============================>.] - ETA: 0s - loss: 0.1096 - accuracy: 0.9630"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 7s 12ms/step - loss: 0.1099 - accuracy: 0.9628 - val_loss: 0.1335 - val_accuracy: 0.9633\n",
      "Epoch 27/200\n",
      "600/602 [============================>.] - ETA: 0s - loss: 0.1064 - accuracy: 0.9646"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 7s 11ms/step - loss: 0.1063 - accuracy: 0.9647 - val_loss: 0.1266 - val_accuracy: 0.9633\n",
      "Epoch 28/200\n",
      "598/602 [============================>.] - ETA: 0s - loss: 0.0995 - accuracy: 0.9670"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 7s 11ms/step - loss: 0.1013 - accuracy: 0.9666 - val_loss: 0.1384 - val_accuracy: 0.9550\n",
      "Epoch 29/200\n",
      "597/602 [============================>.] - ETA: 0s - loss: 0.0981 - accuracy: 0.9665"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: callback_folder/Sheila-NormDoubleConvModel_Jul23_17-30-52/ckpts/cp.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "602/602 [==============================] - 7s 11ms/step - loss: 0.0980 - accuracy: 0.9666 - val_loss: 0.1366 - val_accuracy: 0.9583\n"
     ]
    }
   ],
   "source": [
    "# How many epochs?\n",
    "epochs = 200\n",
    "\n",
    "# Callbacks creaton\n",
    "model_callbacks = create_folders_and_callbacks(model_name)\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    x = training_generator,\n",
    "    epochs = epochs,\n",
    "    validation_data = validation_generator,\n",
    "    callbacks = model_callbacks\n",
    ").history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_nL3y-sPJ84"
   },
   "source": [
    "Evaluate the trained model on the testing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qr7ku40VPUC1",
    "outputId": "1a3717c4-1293-4d33-9509-245767e20e8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/75 [=>............................] - ETA: 1s - loss: 0.1166 - accuracy: 0.9583"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-23 17:35:01.317077: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 1s 12ms/step - loss: 0.1254 - accuracy: 0.9600\n"
     ]
    }
   ],
   "source": [
    "model_metrics = model.evaluate(testing_generator, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zKVmbw3TO6zy"
   },
   "source": [
    "## Saving and exporting the trained model\n",
    "\n",
    "This last section takes care of saving and exporting the trained model in .h5 format, in order to process it through the Infineon ML Configurator Tool available in Modus Toolbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DWXaq62rp-il",
    "outputId": "cce71415-b4fc-404a-9672-46f7b20f9055"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/Sheila-NormDoubleConvModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/Sheila-NormDoubleConvModel/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(os.path.join('models', model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ssuU7nT5np6v",
    "outputId": "65636840-9487-4a8d-d7c2-f58e9801112d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/75 [..............................] - ETA: 12s - loss: 0.0153 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-23 17:35:16.583655: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 1s 12ms/step - loss: 0.1264 - accuracy: 0.9600\n"
     ]
    }
   ],
   "source": [
    "model = tfk.models.load_model(os.path.join('models', model_name))\n",
    "model_metrics = model.evaluate(testing_generator, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "E6uXucqztD95"
   },
   "outputs": [],
   "source": [
    "h5_model_name = model_name + '.h5'\n",
    "tfk.models.save_model(model, os.path.join('models', h5_model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54_zmMBuC1nS"
   },
   "source": [
    "## Conversion for TFLite Micro\n",
    "The following section will convert the code for a microcontroller with a float and a 8 bit quantization.\n",
    "\n",
    "This is not to be done if you want to use the Infineon IFX engine, because it will take care of this conversion step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HW5Cz9BMC8qA",
    "outputId": "3287e15a-6808-4410-d5d4-9e747aadb42c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpj_o4x2mb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpj_o4x2mb/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float model size: 107176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-23 17:35:43.693987: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-07-23 17:35:43.694046: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-07-23 17:35:43.694309: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpj_o4x2mb\n",
      "2023-07-23 17:35:43.696395: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-07-23 17:35:43.696423: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpj_o4x2mb\n",
      "2023-07-23 17:35:43.701261: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-07-23 17:35:43.733780: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpj_o4x2mb\n",
      "2023-07-23 17:35:43.743339: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 49030 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# Float model export:\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "print(\"Float model size:\", open(os.path.join('models', model_name + '.tflite'), \"wb\").write(tflite_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v5yfoy1_DDK7",
    "outputId": "64cd5380-1665-440e-9dd9-a28746da367f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp9_djljvm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp9_djljvm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model size:  31008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lolepls/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:789: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2023-07-23 17:35:54.490585: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-07-23 17:35:54.490637: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-07-23 17:35:54.490841: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmp9_djljvm\n",
      "2023-07-23 17:35:54.491862: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-07-23 17:35:54.491876: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmp9_djljvm\n",
      "2023-07-23 17:35:54.495463: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-07-23 17:35:54.521828: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmp9_djljvm\n",
      "2023-07-23 17:35:54.530958: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 40116 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    }
   ],
   "source": [
    "# Quantized model export:\n",
    "\n",
    "## Definition of Representative Dataset generator:\n",
    "def representative_data_gen():\n",
    "  for sample in x_rep:\n",
    "    data = sample.reshape(-1, *spectrogram_size, spectrogram_channels).astype(np.float32)\n",
    "    yield [data]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "\n",
    "tflite_model_quant = converter.convert()\n",
    "print(\"Quantized model size: \", open(os.path.join('models', model_name + '-int8.tflite'), \"wb\").write(tflite_model_quant))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3jWIB7NRF7hi"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "snF9dxLqHrBG"
   },
   "source": [
    "### Generate a TensorFlow Lite for Microcontrollers Model\n",
    "To convert the TensorFlow Lite quantized model into a C source file that can be loaded by TensorFlow Lite for Microcontrollers on Arduino we simply need to use the ```xxd``` tool to convert the ```.tflite``` file into a ```.cc``` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wal1izt0F8oq",
    "outputId": "d185307e-ddea-462c-f829-6e5ed283532c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [Working]\r",
      "            \r",
      "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
      "\r",
      "0% [Connecting to archive.ubuntu.com (185.125.190.36)] [Connecting to security.\r",
      "0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (185.125.190.36\r",
      "                                                                               \r",
      "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "\r",
      "0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r",
      "                                                                               \r",
      "Hit:3 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
      "\r",
      "0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r",
      "                                                                               \r",
      "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
      "\r",
      "0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Conn\r",
      "0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpad.net\r",
      "0% [2 InRelease gpgv 242 kB] [Waiting for headers] [Waiting for headers] [Conne\r",
      "                                                                               \r",
      "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Hit:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
      "Hit:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
      "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
      "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
      "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
      "Reading package lists... Done\n"
     ]
    }
   ],
   "source": [
    "!apt-get update && apt-get -qq install xxd\n",
    "\n",
    "MODEL_TFLITE = 'models/TinyConvModel.tflite'\n",
    "MODEL_TFLITE_MICRO = 'TinyConvModel.cc'\n",
    "!xxd -i {MODEL_TFLITE} > {MODEL_TFLITE_MICRO}\n",
    "REPLACE_TEXT = MODEL_TFLITE.replace('/', '_').replace('.', '_')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
